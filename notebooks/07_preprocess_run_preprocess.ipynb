{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numpy version is 1.18.1.\n",
      "The pandas version is 1.0.4.\n",
      "The scikit-learn version is 0.23.1.\n",
      "The matplotlib version is 3.2.1.\n",
      "The regex version is 2.5.80.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# version check\n",
    "import numpy\n",
    "print('The numpy version is {}.'.format(numpy.__version__))\n",
    "import pandas\n",
    "print('The pandas version is {}.'.format(pandas.__version__))\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "import matplotlib\n",
    "print('The matplotlib version is {}.'.format(matplotlib.__version__))\n",
    "import regex\n",
    "print('The regex version is {}.'.format(regex.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random state for reproducibility\n",
    "random_state = 42\n",
    "\n",
    "# default numpy settings\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=3)\n",
    "np.core.arrayprint._line_width = 80\n",
    "\n",
    "# update settings\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=15, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3f\" % x))\n",
    "\n",
    "# update pandas settings\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.options.display.max_rows = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threadpool executor for this notebook's user functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors: 16\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "print(\"Number of processors: %d\" % (os.cpu_count()))\n",
    "\n",
    "def threadpool_executor(io_func=None, df=None, series=None, merge_back=False, idict=None, new_name=None):\n",
    "    \"\"\"Use this to pass a dataframe series to the threadpool executor to trigger async processessing. Make sure the user function (io_func) meets the following conditions:\n",
    "    - Receives two arguments: series index position & series values\n",
    "    - Has an output dictionary that assembles the index, values as key, values for reassembly\n",
    "    - Output dictionary is set as the return by name within the called function\n",
    "    \n",
    "    io_func: user function to pass to threadpoolexecutor; df: dataframe with data; series: string name of column; idict: dictionary linked to user function to catch output values; new_name: string for new column name\n",
    "    when reassigning values back to the main dataframe\"\"\"\n",
    "    \n",
    "    if (io_func is None) | (df is None) | (series is None):\n",
    "        sys.exit(\"'None' received as input for either io_func, df, or series. Please assign a value and try again.\")\n",
    "    if (merge_back is True) & (idict is None):\n",
    "        sys.exit(\"'merge_back is set to True. However, no dictionary has been passed to capture output. Please set the idict= argument to an initialized dictionary and try again.'\")\n",
    "    \n",
    "    import concurrent.futures\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:  \n",
    "        executor.map(io_func, df[series].index, df[series])\n",
    "    \n",
    "    if merge_back == True: # will merge the processed values back to the initial dataframe\n",
    "        if idict is not None:\n",
    "            new_frame = pd.DataFrame.from_dict(idict, orient='index')\n",
    "            if new_name is not None:\n",
    "                new_frame.columns = [new_name]\n",
    "                df = pd.merge(df, new_frame, how='left', left_index=True, right_index=True, copy=False)\n",
    "            else:\n",
    "                sys.exit(\"Merge back is True, but no series or name for a new column has been received. If a new column is desired, please pass a new_name. Otherwise, please pass, 'series' to merge_back to replace the current series.\")\n",
    "    if merge_back == 'series': # will drop the old series and replace it with the new processed documents\n",
    "        df = df.drop(series, axis=1)\n",
    "        new_frame = pd.DataFrame.from_dict(idict, orient='index')\n",
    "        new_frame.columns = [series]\n",
    "        df = pd.merge(df, new_frame, how='left', left_index=True, right_index=True, copy=False)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import dataframe, drop duplicates\n",
    "dataset_directory = './data/enron/clean_clean_by_strings.csv'\n",
    "Corpus_input = 'clean_body'\n",
    "Corpus_output = 'preprocessed_body'\n",
    "df = pd.read_csv(dataset_directory, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_dir</th>\n",
       "      <th>m_id</th>\n",
       "      <th>m_date</th>\n",
       "      <th>m_from</th>\n",
       "      <th>m_to</th>\n",
       "      <th>m_cc</th>\n",
       "      <th>m_bcc</th>\n",
       "      <th>m_subj</th>\n",
       "      <th>mime_vers</th>\n",
       "      <th>cont_type</th>\n",
       "      <th>...</th>\n",
       "      <th>x_orig</th>\n",
       "      <th>x_fname</th>\n",
       "      <th>o_body</th>\n",
       "      <th>m_body</th>\n",
       "      <th>gender</th>\n",
       "      <th>n_emails_sent</th>\n",
       "      <th>n_characters_start</th>\n",
       "      <th>clean_char</th>\n",
       "      <th>n_char</th>\n",
       "      <th>clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/enron/maildir/farmer-d/logistics/12</td>\n",
       "      <td>&lt;18632438.1075840432068.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Tue, 11 Dec 2001 06:07:33 -0800 (PST)</td>\n",
       "      <td>rita.wynne@enron.com</td>\n",
       "      <td>michael.olsen@enron.com, stephen.swisher@enron.com</td>\n",
       "      <td>sherry.anastas@enron.com, j..farmer@enron.com</td>\n",
       "      <td>sherry.anastas@enron.com, j..farmer@enron.com</td>\n",
       "      <td>Centana Storage Deal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>...</td>\n",
       "      <td>FARMER-D</td>\n",
       "      <td>darren farmer 6-26-02.pst\\n\\n</td>\n",
       "      <td>Message-ID: &lt;18632438.1075840432068.JavaMail.evans@thyme&gt;\\nDate: Tue, 11 Dec 2001 06:07:33 -0800 (PST)\\nFrom: rita.wynne@enron.com\\nTo: michael.olsen@enron.com, stephen.swisher@enron.com\\nSubject:...</td>\n",
       "      <td>Mike/Stephen,\\n\\nHave the two of you been able to get the deal in for the sale of the Centana storage to AEP?  Please advise.  I would like to have this completed for this close if possible.\\n\\nDa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>Mike/Stephen,\\n\\nHave the two of you been able to get the deal in for the sale of the Centana storage to AEP?  Please advise.  I would like to have this completed for this close if possible.\\n\\nDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/enron/maildir/guzman-m/all_documents/1429</td>\n",
       "      <td>&lt;18190482.1075840619280.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 21 Dec 2000 04:07:00 -0800 (PST)</td>\n",
       "      <td>caroline.emmert@enron.com</td>\n",
       "      <td>geir.solberg@enron.com, holden.salisbury@enron.com, mark.guzman@enron.com</td>\n",
       "      <td>virginia.thompson@enron.com</td>\n",
       "      <td>virginia.thompson@enron.com</td>\n",
       "      <td>Puget Sound Deal on October 17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>...</td>\n",
       "      <td>GUZMAN-M</td>\n",
       "      <td>mark guzman 6-28-02.nsf\\n\\n</td>\n",
       "      <td>Message-ID: &lt;18190482.1075840619280.JavaMail.evans@thyme&gt;\\nDate: Thu, 21 Dec 2000 04:07:00 -0800 (PST)\\nFrom: caroline.emmert@enron.com\\nTo: geir.solberg@enron.com, holden.salisbury@enron.com, mar...</td>\n",
       "      <td>Guys,\\n\\nPuget is claiming that we did a real-time deal with their trader, Lisa, on \\nOctober 17 HE 20.  The terms are 20MW purchased from Puget at a rate of \\n$115.  We cannot find anything in th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>Guys,\\n\\nPuget is claiming that we did a real-time deal with their trader, Lisa, on \\nOctober 17 HE 20.  The terms are 20MW purchased from Puget at a rate of \\n$115.  We cannot find anything in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              f_dir  \\\n",
       "0        ./data/enron/maildir/farmer-d/logistics/12   \n",
       "1  ./data/enron/maildir/guzman-m/all_documents/1429   \n",
       "\n",
       "                                            m_id  \\\n",
       "0  <18632438.1075840432068.JavaMail.evans@thyme>   \n",
       "1  <18190482.1075840619280.JavaMail.evans@thyme>   \n",
       "\n",
       "                                  m_date                     m_from  \\\n",
       "0  Tue, 11 Dec 2001 06:07:33 -0800 (PST)       rita.wynne@enron.com   \n",
       "1  Thu, 21 Dec 2000 04:07:00 -0800 (PST)  caroline.emmert@enron.com   \n",
       "\n",
       "                                                                        m_to  \\\n",
       "0                         michael.olsen@enron.com, stephen.swisher@enron.com   \n",
       "1  geir.solberg@enron.com, holden.salisbury@enron.com, mark.guzman@enron.com   \n",
       "\n",
       "                                            m_cc  \\\n",
       "0  sherry.anastas@enron.com, j..farmer@enron.com   \n",
       "1                    virginia.thompson@enron.com   \n",
       "\n",
       "                                           m_bcc  \\\n",
       "0  sherry.anastas@enron.com, j..farmer@enron.com   \n",
       "1                    virginia.thompson@enron.com   \n",
       "\n",
       "                           m_subj  mime_vers                     cont_type  \\\n",
       "0            Centana Storage Deal        1.0  text/plain; charset=us-ascii   \n",
       "1  Puget Sound Deal on October 17        1.0  text/plain; charset=us-ascii   \n",
       "\n",
       "   ...    x_orig                        x_fname  \\\n",
       "0  ...  FARMER-D  darren farmer 6-26-02.pst\\n\\n   \n",
       "1  ...  GUZMAN-M    mark guzman 6-28-02.nsf\\n\\n   \n",
       "\n",
       "                                                                                                                                                                                                    o_body  \\\n",
       "0  Message-ID: <18632438.1075840432068.JavaMail.evans@thyme>\\nDate: Tue, 11 Dec 2001 06:07:33 -0800 (PST)\\nFrom: rita.wynne@enron.com\\nTo: michael.olsen@enron.com, stephen.swisher@enron.com\\nSubject:...   \n",
       "1  Message-ID: <18190482.1075840619280.JavaMail.evans@thyme>\\nDate: Thu, 21 Dec 2000 04:07:00 -0800 (PST)\\nFrom: caroline.emmert@enron.com\\nTo: geir.solberg@enron.com, holden.salisbury@enron.com, mar...   \n",
       "\n",
       "                                                                                                                                                                                                    m_body  \\\n",
       "0  Mike/Stephen,\\n\\nHave the two of you been able to get the deal in for the sale of the Centana storage to AEP?  Please advise.  I would like to have this completed for this close if possible.\\n\\nDa...   \n",
       "1  Guys,\\n\\nPuget is claiming that we did a real-time deal with their trader, Lisa, on \\nOctober 17 HE 20.  The terms are 20MW purchased from Puget at a rate of \\n$115.  We cannot find anything in th...   \n",
       "\n",
       "  gender n_emails_sent n_characters_start clean_char n_char  \\\n",
       "0    1.0            57                268        268    268   \n",
       "1    1.0            90                479        479    479   \n",
       "\n",
       "                                                                                                                                                                                                clean_body  \n",
       "0  Mike/Stephen,\\n\\nHave the two of you been able to get the deal in for the sale of the Centana storage to AEP?  Please advise.  I would like to have this completed for this close if possible.\\n\\nDa...  \n",
       "1  Guys,\\n\\nPuget is claiming that we did a real-time deal with their trader, Lisa, on \\nOctober 17 HE 20.  The terms are 20MW purchased from Puget at a rate of \\n$115.  We cannot find anything in th...  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring impact on labels\n",
    "We want to keep an eye on the male/female ratio when filtering out our dataset (especially when blanket removing things like 'duplicates', where the filtering can be applied to either label for the same condition) so that our label ratio isn't significantly unbalanced as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 170545 observations\n",
      "boy: 96240\n",
      "girl: 74305\n",
      "B/G Ratio: 1.295 (56%, 44%)\n"
     ]
    }
   ],
   "source": [
    "def monitor_label(df):\n",
    "    b = df.groupby(['gender']).size()[0]\n",
    "    g = df.groupby(['gender']).size()[1]\n",
    "    print('Frame Size: {} observations\\nboy: {}\\ngirl: {}\\nB/G Ratio: {:.3f} ({:.0f}%, {:.0f}%)'.format(len(df), b, g, b/g, b*100/(b+g), g*100/(b+g)))\n",
    "    \n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN from gender, message body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 170545 observations\n",
      "boy: 96240\n",
      "girl: 74305\n",
      "B/G Ratio: 1.295 (56%, 44%)\n"
     ]
    }
   ],
   "source": [
    "df = df[df.gender.notna()]\n",
    "df = df[df[Corpus_input].notna()]\n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates from cleaned email body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 156373 observations\n",
      "boy: 87147\n",
      "girl: 69226\n",
      "B/G Ratio: 1.259 (56%, 44%)\n"
     ]
    }
   ],
   "source": [
    "# set dataframe to dropped duplicates\n",
    "df = df.drop_duplicates(Corpus_input)\n",
    "\n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_frame(df):\n",
    "    df = df.sample(n=len(df)).reset_index(drop=True)\n",
    "    return df\n",
    "df = resample_frame(df) # resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test samples for preprocess function setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the largest email body for preprocessing setup\n",
    "test_sample = df[Corpus_input].max()\n",
    "test_samples = df.loc[0:20, Corpus_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimbo, thank you for the message.  I, too, have great, ever-lasting memories of our times together in Spain and Scottsdale. I am confident that there will be many more to come.  Please let me know how much longer you will be in Spain so that I can attempt to visit you again.  You have wonderful skills and integrity and a very big and caring heart, and you will do extremely well in whatever career life offers you. I am proud to be your father.  Love, Dad \n",
      "\n",
      " \n",
      "I have tracked down an old memo written by the Chief Counsel of Federal \n",
      "Affairs for Niagara Mohawk, summarizing positions taken in requests for \n",
      "rehearing of Order No. 888 to close the bypass loophole.  She discusses how \n",
      "there would be many efforts to municipalize utilities' distribution systems \n",
      "in New York and how NiMo would be meeting with the FERC Staff to tell them \n",
      "how much money they might lose if they couldn't figure out a way to recover \n",
      "these costs.  Maybe whoever is researching this should focus on FERC cases \n",
      "involving New York utilities.  \n",
      "\n",
      "\n",
      "Well, how does it feel to be back?  I'm sure, even though our fair city can't \n",
      "compete with London for history and culture, there are a few things you've \n",
      "missed about this place.  Hope the flight back was good and I'm sure I'll be \n",
      "seeing you around.\n",
      "\n",
      "Susan\n"
     ]
    }
   ],
   "source": [
    "for sample in test_samples[:3]:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words & Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 samples from stop_words list: ['from', 'some', 'd', \"mightn't\", 'him', 'when', \"hadn't\", 'whom', 'before', 'such']\n",
      "10 samples from new stop_words list: ['nedre', 'cathlene', 'jason', 'orton', 'goradia', 'mina', 'weezie', 'kanya', 'ring', 'saundra']\n",
      "stop_words count: 179\n",
      "names from file: 12418\n",
      "stop_words_names count: 12591\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "_ = list(stop_words)[:10]\n",
    "print('10 samples from stop_words list: %s' % (_[:10]))\n",
    "names_from_file = pd.read_csv('./data/names/all_names.txt', sep='\\n', header=None)\n",
    "names_list = list(names_from_file[0].str.lower())\n",
    "stop_words_names = names_list.copy()\n",
    "stop_words_names.extend(list(stop_words))\n",
    "print('10 samples from new stop_words list: %s' % (stop_words_names[:10]))\n",
    "stop_words_names = set(stop_words_names)\n",
    "print('stop_words count: %d\\nnames from file: %d\\nstop_words_names count: %d' % (len(stop_words), len(names_list), len(stop_words_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import regex\n",
    "import regex as re\n",
    "# import lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize # creates tokenized words\n",
    "# instantiate stemmer object\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "rem_nword_char = re.compile(r'\\W') # remove characters that are not word characters\n",
    "rem_underscore = re.compile(r'_+', flags=re.I) # removes the underscore character\n",
    "rem_single_char = re.compile(r'\\b\\w\\b', flags=re.I) # removes all single characters\n",
    "rem_numbers = re.compile(r'\\d') # removes numbers\n",
    "rem_mult_spaces = re.compile(r'\\s+', flags=re.I) # reduces multiple spaces to single space\n",
    "\n",
    "def process_text(doc_idx, doc):\n",
    "    try:\n",
    "        doc = re.sub(rem_nword_char, ' ', str(doc)) # remove characters that are not word characters\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        doc = re.sub(rem_underscore, ' ', str(doc)) # removes the underscore character\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        doc = re.sub(rem_single_char, ' ', str(doc)) # removes all single characters\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        doc = re.sub(rem_numbers, ' ', str(doc)) # removes numbers\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        doc = doc.lower()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        doc = re.sub(rem_mult_spaces, ' ', str(doc)) # reduces multiple spaces to single space\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        doc = ' '.join([stemmer.lemmatize(word) for word in word_tokenize(doc) if word not in stop_words_names])\n",
    "        #doc = ' '.join([stemmer.lemmatize(word) for word in doc.split() if word not in stop_words_names])\n",
    "        #doc = ' '.join([word for word in word_tokenize(doc) if word not in stop_words_names])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    returns_dict[doc_idx] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 156373 observations\n",
      "boy: 87147\n",
      "girl: 69226\n",
      "B/G Ratio: 1.259 (56%, 44%)\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "returns_dict = {} # call threadpool user function, pass signature args\n",
    "df = threadpool_executor(io_func=process_text, df=df, series=Corpus_input, merge_back=True, idict=returns_dict, new_name=Corpus_output)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156373"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(returns_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Messages: Remove rows where processed message is NaN (pd.notna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 156373 observations\n",
      "boy: 87147\n",
      "girl: 69226\n",
      "B/G Ratio: 1.259 (56%, 44%)\n"
     ]
    }
   ],
   "source": [
    "df = df[df[Corpus_output].notna()]\n",
    "df = df.reset_index(drop=True)\n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Messages: Remove rows where processed message equals a blank (== '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 154021 observations\n",
      "boy: 85683\n",
      "girl: 68338\n",
      "B/G Ratio: 1.254 (56%, 44%)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(np.where(df[Corpus_output] == '')[0])\n",
    "df = df.reset_index(drop=True)\n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Messages: Remove rows where processed message is a duplicate (.drop_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Size: 139283 observations\n",
      "boy: 77155\n",
      "girl: 62128\n",
      "B/G Ratio: 1.242 (55%, 45%)\n"
     ]
    }
   ],
   "source": [
    "# set dataframe to dropped duplicates\n",
    "df = df.drop_duplicates(Corpus_output)\n",
    "df = df.reset_index(drop=True)\n",
    "monitor_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_dir</th>\n",
       "      <th>m_id</th>\n",
       "      <th>m_date</th>\n",
       "      <th>m_from</th>\n",
       "      <th>m_to</th>\n",
       "      <th>m_cc</th>\n",
       "      <th>m_bcc</th>\n",
       "      <th>m_subj</th>\n",
       "      <th>mime_vers</th>\n",
       "      <th>cont_type</th>\n",
       "      <th>...</th>\n",
       "      <th>x_fname</th>\n",
       "      <th>o_body</th>\n",
       "      <th>m_body</th>\n",
       "      <th>gender</th>\n",
       "      <th>n_emails_sent</th>\n",
       "      <th>n_characters_start</th>\n",
       "      <th>clean_char</th>\n",
       "      <th>n_char</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>preprocessed_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/enron/maildir/derrick-j/sent_items/247</td>\n",
       "      <td>&lt;3600822.1075845098335.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 6 Apr 2001 11:54:21 -0700 (PDT)</td>\n",
       "      <td>james.derrick@enron.com</td>\n",
       "      <td>jvd024@hotmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RE:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=ANSI_X3.4-1968</td>\n",
       "      <td>...</td>\n",
       "      <td>Derrick Jr., James.pst\\n\\n</td>\n",
       "      <td>Message-ID: &lt;3600822.1075845098335.JavaMail.evans@thyme&gt;\\nDate: Fri, 6 Apr 2001 11:54:21 -0700 (PDT)\\nFrom: james.derrick@enron.com\\nTo: jvd024@hotmail.com\\nSubject: RE:\\nMime-Version: 1.0\\nConten...</td>\n",
       "      <td>Jimbo, thank you for the message.  I, too, have great, ever-lasting memories of our times together in Spain and Scottsdale. I am confident that there will be many more to come.  Please let me know...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909</td>\n",
       "      <td>1859</td>\n",
       "      <td>461</td>\n",
       "      <td>461</td>\n",
       "      <td>Jimbo, thank you for the message.  I, too, have great, ever-lasting memories of our times together in Spain and Scottsdale. I am confident that there will be many more to come.  Please let me know...</td>\n",
       "      <td>jimbo thank you for the message too have great ever lasting memories of our times together in spain and scottsdale am confident that there will be many more to come please let me know how much lon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           f_dir  \\\n",
       "0  ./data/enron/maildir/derrick-j/sent_items/247   \n",
       "\n",
       "                                           m_id  \\\n",
       "0  <3600822.1075845098335.JavaMail.evans@thyme>   \n",
       "\n",
       "                                 m_date                   m_from  \\\n",
       "0  Fri, 6 Apr 2001 11:54:21 -0700 (PDT)  james.derrick@enron.com   \n",
       "\n",
       "                 m_to m_cc m_bcc m_subj  mime_vers  \\\n",
       "0  jvd024@hotmail.com  NaN   NaN    RE:        1.0   \n",
       "\n",
       "                            cont_type  ...                     x_fname  \\\n",
       "0  text/plain; charset=ANSI_X3.4-1968  ...  Derrick Jr., James.pst\\n\\n   \n",
       "\n",
       "                                                                                                                                                                                                    o_body  \\\n",
       "0  Message-ID: <3600822.1075845098335.JavaMail.evans@thyme>\\nDate: Fri, 6 Apr 2001 11:54:21 -0700 (PDT)\\nFrom: james.derrick@enron.com\\nTo: jvd024@hotmail.com\\nSubject: RE:\\nMime-Version: 1.0\\nConten...   \n",
       "\n",
       "                                                                                                                                                                                                    m_body  \\\n",
       "0  Jimbo, thank you for the message.  I, too, have great, ever-lasting memories of our times together in Spain and Scottsdale. I am confident that there will be many more to come.  Please let me know...   \n",
       "\n",
       "  gender n_emails_sent n_characters_start clean_char n_char  \\\n",
       "0    0.0           909               1859        461    461   \n",
       "\n",
       "                                                                                                                                                                                                clean_body  \\\n",
       "0  Jimbo, thank you for the message.  I, too, have great, ever-lasting memories of our times together in Spain and Scottsdale. I am confident that there will be many more to come.  Please let me know...   \n",
       "\n",
       "                                                                                                                                                                                         preprocessed_body  \n",
       "0  jimbo thank you for the message too have great ever lasting memories of our times together in spain and scottsdale am confident that there will be many more to come please let me know how much lon...  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139283 entries, 0 to 139282\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   f_dir               139283 non-null  object \n",
      " 1   m_id                139283 non-null  object \n",
      " 2   m_date              139283 non-null  object \n",
      " 3   m_from              139283 non-null  object \n",
      " 4   m_to                136997 non-null  object \n",
      " 5   m_cc                44984 non-null   object \n",
      " 6   m_bcc               42944 non-null   object \n",
      " 7   m_subj              133440 non-null  object \n",
      " 8   mime_vers           139283 non-null  float64\n",
      " 9   cont_type           139283 non-null  object \n",
      " 10  encode              139283 non-null  object \n",
      " 11  x_from              139283 non-null  object \n",
      " 12  x_to                137591 non-null  object \n",
      " 13  x_cc                43246 non-null   object \n",
      " 14  x_bcc               117 non-null     object \n",
      " 15  x_fold              139283 non-null  object \n",
      " 16  x_orig              139283 non-null  object \n",
      " 17  x_fname             139283 non-null  object \n",
      " 18  o_body              139283 non-null  object \n",
      " 19  m_body              139283 non-null  object \n",
      " 20  gender              139283 non-null  float64\n",
      " 21  n_emails_sent       139283 non-null  int64  \n",
      " 22  n_characters_start  139283 non-null  int64  \n",
      " 23  clean_char          139283 non-null  int64  \n",
      " 24  n_char              139283 non-null  int64  \n",
      " 25  clean_body          139283 non-null  object \n",
      " 26  preprocessed_body   139283 non-null  object \n",
      "dtypes: float64(2), int64(4), object(21)\n",
      "memory usage: 28.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/enron/preprocess_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 411.8s (~6m)\n"
     ]
    }
   ],
   "source": [
    "end_time = time.perf_counter()\n",
    "print('Run time: %.1fs (~%dm)' % ((end_time-start_time, (end_time-start_time)/60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
