{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.23.1.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set data to df\n",
    "email_data = pd.read_csv('./data/enron/03_mini_processing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = email_data[['m_body', 'gender']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "boy     90037\n",
       "girl    68731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby(['gender']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclassify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool target variables: boy = 0, girl = 1\n",
    "full_df.gender = full_df.gender.replace('boy', 0)\n",
    "full_df.gender = full_df.gender.replace('girl', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reclassify data into arrays\n",
    "full_X = full_df.m_body.values # features\n",
    "full_y = full_df.gender.values # targets (gender labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample subset for initial tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# set number of samples\n",
    "n_samples = 1000\n",
    "\n",
    "# random choice collect index\n",
    "sample_idx = np.random.choice(np.arange(len(full_X)), size=n_samples, replace=True)\n",
    "\n",
    "# create sample subsets\n",
    "Xs = full_X[sample_idx]\n",
    "ys = full_y[sample_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "### countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 ms ± 2.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate vectorizer\n",
    "count_vect = CountVectorizer()\n",
    "# fit to data\n",
    "%timeit count_vect.fit_transform(Xs)\n",
    "Xs_vect = count_vect.fit_transform(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The ENW Staff Mtg. has been CANCELED for this week(11/16) and next week(11/23 ). The meeting will resume on Thursday, November 30th. Happy Thanksgiving! Tammie\n",
      "Type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Shape: (1000, 12190)\n",
      "Vector data: [1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# countvector review\n",
    "print('Input: {}'.format(Xs[3]))\n",
    "print('Type: {}'.format(type(Xs_vect)))\n",
    "print('Shape: {}'.format(Xs_vect.shape))\n",
    "print('Vector data: {}'.format(Xs_vect[3].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### term frequency (tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 µs ± 7.47 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# fit estimator to vectored data\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(Xs_vect)\n",
    "# tranform count-matrix to tf-idf representation\n",
    "%timeit tf_transformer.transform(Xs_vect)\n",
    "Xs_tf = tf_transformer.transform(Xs_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The ENW Staff Mtg. has been CANCELED for this week(11/16) and next week(11/23 ). The meeting will resume on Thursday, November 30th. Happy Thanksgiving! Tammie\n",
      "Type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Shape: (1000, 12190)\n",
      "Vector data: [0.34299717 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      " 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      " 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859 0.17149859\n",
      " 0.17149859 0.17149859 0.34299717 0.17149859 0.17149859 0.34299717\n",
      " 0.17149859]\n"
     ]
    }
   ],
   "source": [
    "# tf review\n",
    "print('Input: {}'.format(Xs[3]))\n",
    "print('Type: {}'.format(type(Xs_tf)))\n",
    "print('Shape: {}'.format(Xs_tf.shape))\n",
    "print('Vector data: {}'.format(Xs_tf[3].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### term frequency inverse document frequency (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 ms ± 41.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# instantiate model\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# fit, transform\n",
    "%timeit tfidf_transformer.fit_transform(Xs_vect)\n",
    "Xs_tfidf = tfidf_transformer.fit_transform(Xs_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The ENW Staff Mtg. has been CANCELED for this week(11/16) and next week(11/23 ). The meeting will resume on Thursday, November 30th. Happy Thanksgiving! Tammie\n",
      "Type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Shape: (1000, 12190)\n",
      "Vector data: [0.09328117 0.28143476 0.17419165 0.08180764 0.11706943 0.25250261\n",
      " 0.28111494 0.19359287 0.22389028 0.08136966 0.19886969 0.14715706\n",
      " 0.29785208 0.14405969 0.11827755 0.19359287 0.07328471 0.28111494\n",
      " 0.26002864 0.13132321 0.06903416 0.26923975 0.19359287 0.18606684\n",
      " 0.28912009]\n"
     ]
    }
   ],
   "source": [
    "# tf review\n",
    "print('Input: {}'.format(Xs[3]))\n",
    "print('Type: {}'.format(type(Xs_tfidf)))\n",
    "print('Shape: {}'.format(Xs_tfidf.shape))\n",
    "print('Vector data: {}'.format(Xs_tfidf[3].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive bayes (MNB): single classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate 20 'new samples' or unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718 µs ± 17.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# import model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# simulating 20 'new samples' or unlabeled data\n",
    "%timeit train_test_split(Xs_tfidf, ys, test_size=0.02, random_state=42)\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs_tfidf, ys, test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# create model object, fit model\n",
    "mnb = MultinomialNB().fit(Xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "ys_pred = mnb.predict(Xs_test)\n",
    "\n",
    "# checking the prediction\n",
    "#print('Prediction: {}'.format(ys_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single predict: metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.65\n",
      "Confusion matrix:\n",
      "[[11  0]\n",
      " [ 7  2]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        11\n",
      "           1       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.81      0.61      0.56        20\n",
      "weighted avg       0.79      0.65      0.58        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# calculate model accuracy\n",
    "print('accuracy: {}'.format(np.mean(ys_pred == ys_test)))\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(ys_test, ys_pred))\n",
    "\n",
    "# classification report\n",
    "print('Classification report:')\n",
    "print(classification_report(ys_test, ys_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB 60/40 Train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.575\n",
      "Confusion matrix:\n",
      "[[210   2]\n",
      " [168  20]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71       212\n",
      "           1       0.91      0.11      0.19       188\n",
      "\n",
      "    accuracy                           0.57       400\n",
      "   macro avg       0.73      0.55      0.45       400\n",
      "weighted avg       0.72      0.57      0.47       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 60% train, 40% test\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs_tfidf, ys, test_size=0.4, random_state=42)\n",
    "\n",
    "# create model object, fit model\n",
    "mnb = MultinomialNB().fit(Xs_train, ys_train)\n",
    "\n",
    "# prediction\n",
    "ys_pred = mnb.predict(Xs_test)\n",
    "\n",
    "# print the predictions\n",
    "#print('Prediction: {}'.format(ys_pred))\n",
    "\n",
    "# calculate model accuracy\n",
    "print('accuracy: {}'.format(np.mean(ys_pred == ys_test)))\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(ys_test, ys_pred))\n",
    "\n",
    "# classification report\n",
    "print('Classification report:')\n",
    "print(classification_report(ys_test, ys_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB: 10-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV Scores\n",
      "Mean accuracy: 0.65\n",
      "Std accuracy: 0.042\n",
      "accuracy scores: [0.63 0.68 0.69 0.68 0.74 0.64 0.62 0.63 0.58 0.65]\n",
      "Mean precision: 0.83\n",
      "Std precision: 0.13\n",
      "precision scores: [0.66666667 0.86666667 0.875      0.86666667 1.         0.83333333\n",
      " 0.75       1.         0.58333333 0.84615385]\n",
      "Mean recall: 0.26\n",
      "Std recall: 0.072\n",
      "recall scores: [0.27906977 0.30232558 0.3255814  0.30232558 0.39534884 0.22727273\n",
      " 0.20454545 0.15909091 0.15909091 0.25      ]\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# create model object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# compute 10-fold cross-validation\n",
    "scores_list = ['accuracy', 'precision', 'recall']\n",
    "\n",
    "# print scores\n",
    "print('10-Fold CV Scores')\n",
    "for s in scores_list:\n",
    "    cv_scores = cross_val_score(mnb, Xs_tfidf, ys, cv=10, scoring=s, n_jobs=-1)\n",
    "    print('Mean {}: {:1.2g}'.format(s, np.mean(cv_scores)))\n",
    "    print('Std {}: {:1.2g}'.format(s, np.std(cv_scores)))\n",
    "    print('{} scores: {}'.format(s, cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation time trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Fold:\n",
      "6.66 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3-Fold, all processors:\n",
      "10.5 ms ± 173 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5-Fold:\n",
      "10.7 ms ± 141 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5-Fold, all processors:\n",
      "13.1 ms ± 209 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "10-Fold:\n",
      "20.8 ms ± 341 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "10-Fold, all processors:\n",
      "22 ms ± 937 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# cross-validation times\n",
    "#cv_iterations = [3, 5, 10]\n",
    "#for i in cv_iterations:\n",
    "#    print('{}-Fold:'.format(i))\n",
    "#    %timeit cross_val_score(mnb, Xs_tfidf, ys, cv=i)\n",
    "#    print('{}-Fold, all processors:'.format(i))\n",
    "#    %timeit cross_val_score(mnb, Xs_tfidf, ys, cv=i, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB: pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210   2]\n",
      " [166  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71       212\n",
      "           1       0.92      0.12      0.21       188\n",
      "\n",
      "    accuracy                           0.58       400\n",
      "   macro avg       0.74      0.55      0.46       400\n",
      "weighted avg       0.73      0.58      0.48       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# import model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# set steps for pipeline\n",
    "steps = [('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('mnb', MultinomialNB()),]\n",
    "\n",
    "# create pipeline object\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create train and test sets\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, ys, test_size=0.4, random_state=42)\n",
    "\n",
    "# fit model to data\n",
    "pipeline.fit(Xs_train, ys_train)\n",
    "\n",
    "# predict\n",
    "ys_pred = pipeline.predict(Xs_test)\n",
    "\n",
    "# generate confusion matrix, classification report\n",
    "print(confusion_matrix(ys_test, ys_pred))\n",
    "print(classification_report(ys_test, ys_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive bayes: GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199  13]\n",
      " [132  56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       212\n",
      "           1       0.81      0.30      0.44       188\n",
      "\n",
      "    accuracy                           0.64       400\n",
      "   macro avg       0.71      0.62      0.58       400\n",
      "weighted avg       0.70      0.64      0.59       400\n",
      "\n",
      "Tuned MNB Parameters: {'mnb__alpha': 0.1, 'mnb__fit_prior': True, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Tuned MNB Accuracy: 0.6716666666666666\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def mnb_gridsearchcv(X, y, cv_n=10, test_size=0.4, random_state=42):\n",
    "    \"\"\"Pass features, target datasets and return MNB parameters, related accuracy\"\"\"\n",
    "    # import feature extraction\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    # import model\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    # import pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # import model selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    \n",
    "    # set steps for pipeline\n",
    "    steps = [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('mnb', MultinomialNB()),\n",
    "    ]\n",
    "\n",
    "    # create pipeline object\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # specify the parameters\n",
    "    parameters = {\n",
    "        'mnb__alpha':(1.0, 0, 1e-1, 1e-2, 1e-3),\n",
    "    }\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    mnb_cv = GridSearchCV(pipeline, param_grid=parameters, cv=cv_n, n_jobs=-1)\n",
    "\n",
    "    # fit model to data\n",
    "    mnb_cv.fit(X_train, y_train)\n",
    "\n",
    "    # predict test labels\n",
    "    y_pred = mnb_cv.predict(X_test)\n",
    "\n",
    "    # generate confusion matrix, classification report\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print params\n",
    "    print('Tuned MNB Parameters: {}'.format(mnb_cv.best_params_))\n",
    "    print('Tuned MNB Accuracy: {}'.format(mnb_cv.best_score_))\n",
    "\n",
    "mnb_gridsearchcv(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (logreg): GridSearchCV\n",
    "- Logistic Regression (aka logit, MaxEnt) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156  56]\n",
      " [ 75 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.70       212\n",
      "           1       0.67      0.60      0.63       188\n",
      "\n",
      "    accuracy                           0.67       400\n",
      "   macro avg       0.67      0.67      0.67       400\n",
      "weighted avg       0.67      0.67      0.67       400\n",
      "\n",
      "Tuned Logreg Parameters: {'logreg__C': 19306.977288832535, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Tuned Logreg Accuracy: 0.6733333333333335\n",
      "Wall time: 29.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def logreg_gridsearchcv(X, y, cv_n=10, test_size=0.4, random_state=42):\n",
    "    \"\"\"\"\"\"\n",
    "    # import feature extraction\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    # import model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # import pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # import model selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    \n",
    "    # set steps for pipeline\n",
    "    steps = [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('logreg', LogisticRegression()),\n",
    "    ]\n",
    "\n",
    "    # create pipeline object\n",
    "    pipeline = Pipeline(steps)\n",
    "    \n",
    "    # Create the hyperparameter grid\n",
    "    c_space = np.logspace(-5, 8, 15)\n",
    "    parameters = {\n",
    "        'logreg__C': c_space, \n",
    "        'logreg__penalty': ['l1', 'l2'],\n",
    "        'logreg__n_jobs': [-1],\n",
    "    }\n",
    "    \n",
    "#    parameters = {\n",
    "#        'vect__ngram_range':[(1, 1), (1, 2)],\n",
    "#        'tfidf__use_idf':(True, False),\n",
    "#        'logreg__C':[1, 10, 100],\n",
    "#        'logreg__n_jobs': [-1],\n",
    "#    }\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    logreg_cv = GridSearchCV(pipeline, param_grid=parameters, cv=cv_n, n_jobs=-1)\n",
    "\n",
    "    # fit model to data\n",
    "    logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "    # predict test labels\n",
    "    y_pred = logreg_cv.predict(X_test)\n",
    "\n",
    "    # generate confusion matrix, classification report\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print params\n",
    "    print('Tuned Logreg Parameters: {}'.format(logreg_cv.best_params_))\n",
    "    print('Tuned Logreg Accuracy: {}'.format(logreg_cv.best_score_))\n",
    "\n",
    "logreg_gridsearchcv(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent classifier (SGDC): GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147  65]\n",
      " [ 65 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       212\n",
      "           1       0.65      0.65      0.65       188\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.67      0.67      0.67       400\n",
      "weighted avg       0.68      0.68      0.68       400\n",
      "\n",
      "Tuned SGDC Parameters: {'sgdc__alpha': 1e-05, 'sgdc__random_state': 42, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Tuned SGDC Accuracy: 0.6833333333333333\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def sgdc_gridsearchcv(X, y, cv_n=10, test_size=0.4, random_state=42):\n",
    "    \"\"\"Pass features, target datasets and return MNB parameters, related accuracy\"\"\"\n",
    "    # import feature extraction\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    # import model\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    # import pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # import model selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    \n",
    "    # pipeline steps\n",
    "    steps = [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('sgdc', SGDClassifier())\n",
    "    ]\n",
    "    \n",
    "    # pipeline object\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # specify the parameters\n",
    "    parameters = {\n",
    "        'sgdc__alpha':(1e-4, 1e-5, 1e-6),\n",
    "        'sgdc__random_state':[random_state],\n",
    "    }\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # grid search object\n",
    "    sgdc_cv = GridSearchCV(pipeline, param_grid=parameters, cv=cv_n, n_jobs=-1)\n",
    "    \n",
    "    # fit model on training set\n",
    "    sgdc_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # predict test labels\n",
    "    y_pred = sgdc_cv.predict(X_test)\n",
    "    \n",
    "    # generate confusion matrix, classification report\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print params\n",
    "    print('Tuned SGDC Parameters: {}'.format(sgdc_cv.best_params_))\n",
    "    print('Tuned SGDC Accuracy: {}'.format(sgdc_cv.best_score_))\n",
    "    \n",
    "sgdc_gridsearchcv(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-Support Vector Classification (CSVC): GridSearchCV\n",
    "- Impractical beyond tens of thousands of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[172  40]\n",
      " [ 77 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75       212\n",
      "           1       0.74      0.59      0.65       188\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.71      0.70      0.70       400\n",
      "weighted avg       0.71      0.71      0.70       400\n",
      "\n",
      "Tuned CSVC Parameters: {'csvc__C': 100, 'csvc__gamma': 0.1, 'csvc__random_state': 42, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n",
      "Tuned CSVC Accuracy: 0.6666666666666666\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def csvc_gridsearchcv(X, y, cv_n=10, test_size=0.4, random_state=42):\n",
    "    \"\"\"\"\"\"\n",
    "    # \n",
    "    if len(X)>10000:\n",
    "        return \"CSVC skipped: Over 10000 samples received.\"\n",
    "    \n",
    "    # import feature extraction\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    # import model\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    # import pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # import model selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    \n",
    "    # pipeline steps\n",
    "    steps = [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('csvc', SVC())\n",
    "    ]\n",
    "    \n",
    "    # pipeline object\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    parameters = {\n",
    "        'csvc__C':[1, 10, 100],\n",
    "        'csvc__gamma':['scale', 'auto', 0.1, 0.01],\n",
    "        'csvc__random_state':[random_state]\n",
    "    }\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # grid search object\n",
    "    csvc_cv = GridSearchCV(pipeline, param_grid=parameters, cv=cv_n, n_jobs=-1)\n",
    "    \n",
    "    # fit model on training set\n",
    "    csvc_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # predict test labels\n",
    "    y_pred = csvc_cv.predict(X_test)\n",
    "    \n",
    "    # generate confusion matrix, classification report\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print params\n",
    "    print('Tuned CSVC Parameters: {}'.format(csvc_cv.best_params_))\n",
    "    print('Tuned CSVC Accuracy: {}'.format(csvc_cv.best_score_))\n",
    "    \n",
    "csvc_gridsearchcv(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear support vector classification (LSVC): GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[158  54]\n",
      " [ 74 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71       212\n",
      "           1       0.68      0.61      0.64       188\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.68      0.68      0.68       400\n",
      "weighted avg       0.68      0.68      0.68       400\n",
      "\n",
      "Tuned LSVC Parameters: {'lsvc__C': 10, 'lsvc__loss': 'squared_hinge', 'lsvc__penalty': 'l2', 'lsvc__random_state': 42, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n",
      "Tuned LSVC Accuracy: 0.6683333333333334\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def lsvc_gridsearchcv(X, y, cv_n=10, test_size=0.4, random_state=42):\n",
    "    \"\"\"\"\"\"\n",
    "    # import feature extraction\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    # import model\n",
    "    from sklearn.svm import LinearSVC\n",
    "\n",
    "    # import pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # import model selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    \n",
    "    # pipeline steps\n",
    "    steps = [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('lsvc', LinearSVC())\n",
    "    ]\n",
    "    \n",
    "    # pipeline object\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    parameters = {\n",
    "        'lsvc__penalty':['l1', 'l2'],\n",
    "        'lsvc__loss':['hinge', 'squared_hinge'],\n",
    "        'lsvc__C':[1, 10, 100],\n",
    "        'lsvc__random_state':[random_state],\n",
    "    }\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # grid search object\n",
    "    lsvc_cv = GridSearchCV(pipeline, param_grid=parameters, cv=cv_n, n_jobs=-1)\n",
    "    \n",
    "    # fit model on training set\n",
    "    lsvc_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # predict test labels\n",
    "    y_pred = lsvc_cv.predict(X_test)\n",
    "    \n",
    "    # generate confusion matrix, classification report\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print params\n",
    "    print('Tuned LSVC Parameters: {}'.format(lsvc_cv.best_params_))\n",
    "    print('Tuned LSVC Accuracy: {}'.format(lsvc_cv.best_score_))\n",
    "    \n",
    "lsvc_gridsearchcv(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier (RFC): GridSearchCV\n",
    "- sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[195  17]\n",
      " [121  67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       212\n",
      "           1       0.80      0.36      0.49       188\n",
      "\n",
      "    accuracy                           0.66       400\n",
      "   macro avg       0.71      0.64      0.62       400\n",
      "weighted avg       0.70      0.66      0.62       400\n",
      "\n",
      "Tuned RFC Parameters: {'rfc__max_features': 'auto', 'rfc__min_samples_split': 2, 'rfc__n_estimators': 50, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n",
      "Tuned RFC Accuracy: 0.6449999999999999\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rfc_gridsearchcv(X, y, cv_n=10, test_size=0.4, random_state=42):\n",
    "    \"\"\"\"\"\"\n",
    "    # import feature extraction\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    # import model\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # import pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # import model selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    \n",
    "    # pipeline steps\n",
    "    steps = [\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('rfc', RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "    # pipeline object\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    parameters = {\n",
    "        'rfc__n_estimators':[50, 100, 150],\n",
    "        'rfc__max_features':[None, 'auto', 'log2'],\n",
    "        'rfc__n_jobs':[-1],\n",
    "        'rfc__min_samples_split':[2],\n",
    "    }\n",
    "    \n",
    "    # Create train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # grid search object\n",
    "    rfc_cv = GridSearchCV(pipeline, param_grid=parameters, cv=cv_n, n_jobs=-1)\n",
    "    \n",
    "    # fit model on training set\n",
    "    rfc_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # predict test labels\n",
    "    y_pred = rfc_cv.predict(X_test)\n",
    "    \n",
    "    # generate confusion matrix, classification report\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print params\n",
    "    print('Tuned RFC Parameters: {}'.format(rfc_cv.best_params_))\n",
    "    print('Tuned RFC Accuracy: {}'.format(rfc_cv.best_score_))\n",
    "    \n",
    "rfc_gridsearchcv(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 358.99 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# execution time\n",
    "print(\"--- {:1.2f} seconds ---\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-a96ba3aab008>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-a96ba3aab008>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    stop here\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
