{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 1: Data Wrangling\n",
    "\n",
    "**Our Problem:** \n",
    "\n",
    "Can emails be used to identify the author's gender?\n",
    "\n",
    "## Overview\n",
    "For this notebook, our **goal** will be to Acquire, Wrangle, and Clean data from the Enron email dataset.\n",
    "\n",
    "## I. Acquiring the Data\n",
    "The data we'll be working with comes in two forms:\n",
    "- The Enron email dataset\n",
    "- Assumed gender by name\n",
    "\n",
    "The Enron email dataset we'll be working with can be downloaded online from the Carnegie Mellon University School of Computer Science (https://www.cs.cmu.edu/~./enron/) as of March 28, 2020. It comes convieniently zipped under the filename `enron_mail_20150507.tar.gz`.\n",
    "\n",
    "To collect the assumed genders, by name, we'll need to isolate the sender names and decide on a method of identifying gender. We'll return to this once the dataset is cleaned.\n",
    "\n",
    "### Acquiring the Data: Enron Emails\n",
    "\n",
    "Once unzipped, the initial file is `maildir`; we'll call this the *mail directory* (I know - creative). The hierarchy in this file directory goes as such:\n",
    "- Mail Directory ('maildir')\n",
    " - Employee Email Folders\n",
    "  - disorganized mess (folders + emails)\n",
    "\n",
    "Let's use the `os` library to explore the directory with its function `os.scandir()`. We'll evaluate each object returned by `os.scandir()`; if it is another folder, we'll `.append()` it to our list so it will also get explored.\n",
    "\n",
    "Once all the folders have been collected, the second part of the function will iterate through the complete `folder_list` and compile a `file_list` of email file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setup function to return filenames from directory\n",
    "def file_grabber(some_directory):\n",
    "    \"\"\"Returns all files from directory\n",
    "    and child directories by creating, appending\n",
    "    a directory list until all directories are located.\n",
    "    \n",
    "    Then, cycles through each directory and records any\n",
    "    filenames to a list. This list is returned on completion.\"\"\"\n",
    "    \n",
    "    # initialize folder list\n",
    "    folder_list = []\n",
    "\n",
    "    # appends starting folder to folder list\n",
    "    folder_list.append(some_directory)\n",
    "    \n",
    "    # iterate through folder list\n",
    "    for folder in folder_list:\n",
    "        \n",
    "        # open content manager with .scandir() on folder\n",
    "        with os.scandir(folder) as open_folder:\n",
    "\n",
    "            # for each item in the directory folder\n",
    "            for thing in open_folder:\n",
    "\n",
    "                # if the thing is another folder\n",
    "                if thing.is_dir():\n",
    "                    thing_path = (folder + thing.name + '/')\n",
    "                    folder_list.append(thing_path)\n",
    "                else:\n",
    "                    continue\n",
    "      \n",
    "    # print out number of folders\n",
    "    print('{} folders found.'.format(len(folder_list)))\n",
    "    \n",
    "    # initialize file list\n",
    "    file_list = []\n",
    "    \n",
    "    # iterate through folder list to collect filenames\n",
    "    for folder in folder_list:\n",
    "        \n",
    "        # open content manager with .scandir() on folder\n",
    "        with os.scandir(folder) as open_folder:\n",
    "\n",
    "            # for each item in the directory folder\n",
    "            for thing in open_folder:\n",
    "\n",
    "                # if the thing is another folder\n",
    "                if thing.is_file():\n",
    "                    thing_path = (folder + thing.name)\n",
    "                    file_list.append(thing_path)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "    # print out report                    \n",
    "    print('{} files found.'.format(len(file_list)))\n",
    "    \n",
    "    # return files as list\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Function complete.*** Now, let's put it into action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500 folders found.\n",
      "517401 files found.\n"
     ]
    }
   ],
   "source": [
    "# initialize list to collect filenames\n",
    "email_files = []\n",
    "\n",
    "# create base string\n",
    "base_name = './data/maildir/'\n",
    "    \n",
    "# call function to collect file names\n",
    "email_files = file_grabber(base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nice!*** 517401 files found! Let's sort the list and look at some of the filepaths returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/maildir/allen-p/_sent_mail/1',\n",
       " './data/maildir/allen-p/_sent_mail/10',\n",
       " './data/maildir/allen-p/_sent_mail/100',\n",
       " './data/maildir/allen-p/_sent_mail/1000',\n",
       " './data/maildir/allen-p/_sent_mail/1001']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the list\n",
    "email_files.sort()\n",
    "\n",
    "# take a peek\n",
    "email_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Wrangling the Data\n",
    "\n",
    "> Data Wrangling:\n",
    ">\n",
    "> \"The process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as **analytics**.\" - Wikipedia, Data wrangling\n",
    "\n",
    "Let's begin by exploring the *current state of the data*. We'll make notes, and decide what ***wrangling*** we'll need to do. \n",
    "\n",
    "The dataset itself is over 0.5M emails, comes as a *bunch of folders* containing a **bunch of emails** and the unzipped form we'll be working with weighs in around 1.4GB. Let's review an email and isolate some parts to wrangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email reader\n",
    "def read_email(email_path):\n",
    "    \"\"\"returns email body as a body of text\"\"\"\n",
    "    \n",
    "    # file manager opens email file, assigns it to variable\n",
    "    with open(email_path) as email_file:\n",
    "        email_body = email_file.read()\n",
    "    \n",
    "    # returns email body as text\n",
    "    return email_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <33076797.1075855687515.JavaMail.evans@thyme>\n",
      "Date: Mon, 16 Oct 2000 06:42:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: buck.buckner@honeywell.com\n",
      "Subject: Re: FW: fixed forward or other Collar floor gas price terms\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: \"Buckner, Buck\" <buck.buckner@honeywell.com> @ ENRON\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Mr. Buckner,\n",
      "\n",
      " For delivered gas behind San Diego, Enron Energy Services is the appropriate \n",
      "Enron entity.  I have forwarded your request to Zarin Imam at EES.  Her phone \n",
      "number is 713-853-7107.  \n",
      "\n",
      "Phillip Allen\n"
     ]
    }
   ],
   "source": [
    "# email text by line as list\n",
    "print(read_email(email_files[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***To evaluate our problem,*** we need gender and email text.\n",
    "\n",
    "From the email above, we'll collect the `From:` field to capture names (and subsequently, make some assumptions on gender). We'll also need to isolate the email body from the rest of the header information contained in the file. Finally, to keep the data subsets tied to their original forms, we'll preserve the file directory name as an index. \n",
    "\n",
    "Let's tackle this goal in two steps:\n",
    "- Collect the variables of interest in a dictionary using the `re` library\n",
    "- Convert the dictionary to a DataFrame using `pd.DataFrame.from_dict()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import re\n",
    "\n",
    "# custom function\n",
    "def save_to_dict(email_path):\n",
    "    \"\"\"create dictionary from a list of filepath files\n",
    "       returns dictionary\"\"\"\n",
    "\n",
    "    # open email file, get email text\n",
    "    with open(email_path) as open_email:\n",
    "        \n",
    "        # get file text\n",
    "        email_text = open_email.read()\n",
    "        \n",
    "        # get 'Message-ID'\n",
    "        m_id = ''\n",
    "        catch = m_id_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_id = catch[0]         \n",
    "    \n",
    "        # get 'Date'\n",
    "        m_date = ''\n",
    "        catch = m_date_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_date = catch[0]     \n",
    "        \n",
    "        # get 'From'\n",
    "        m_from = ''\n",
    "        catch = m_from_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_from = catch[0] \n",
    "        \n",
    "        # get 'To'\n",
    "        m_to = ''\n",
    "        catch = m_to_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_to = catch[0] \n",
    "\n",
    "        # get 'Cc'\n",
    "        m_cc = ''\n",
    "        catch = m_cc_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_cc = catch[0] \n",
    "        \n",
    "        # get 'Bcc'\n",
    "        m_bcc = ''\n",
    "        catch = m_bcc_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_bcc = catch[0] \n",
    "\n",
    "        # get 'Subject'\n",
    "        m_subj = ''\n",
    "        catch = m_subj_pat.search(email_text)\n",
    "        if catch:\n",
    "            m_subj = catch[0] \n",
    "\n",
    "        # get 'Mime-Version'\n",
    "        mime_vers = ''\n",
    "        catch = mime_vers_pat.search(email_text)\n",
    "        if catch:\n",
    "            mime_vers = catch[0] \n",
    "\n",
    "            # get 'Content-Type'\n",
    "        cont_type = ''\n",
    "        catch = cont_type_pat.search(email_text)\n",
    "        if catch:\n",
    "            cont_type = catch[0] \n",
    "\n",
    "        # get 'Content-Transfer-Encoding'\n",
    "        encode = ''\n",
    "        catch = encode_pat.search(email_text)\n",
    "        if catch:\n",
    "            encode = catch[0] \n",
    "\n",
    "        # get 'X-From'\n",
    "        x_from = ''\n",
    "        catch = x_from_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_from = catch[0] \n",
    "\n",
    "        # get 'X-To'\n",
    "        x_to = ''\n",
    "        catch = x_to_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_to = catch[0] \n",
    "\n",
    "        # get 'X-cc'\n",
    "        x_cc = ''\n",
    "        catch = x_cc_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_cc = catch[0] \n",
    "\n",
    "        # get 'X-bcc'\n",
    "        x_bcc = ''\n",
    "        catch = x_bcc_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_bcc = catch[0] \n",
    "\n",
    "        # get 'X-Folder'\n",
    "        x_fold = ''\n",
    "        catch = x_fold_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_fold = catch[0] \n",
    "\n",
    "        # get 'X-Origin'\n",
    "        x_orig = ''\n",
    "        catch = x_orig_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_orig = catch[0] \n",
    "\n",
    "        # get 'X-Filename'\n",
    "        x_fname = ''\n",
    "        catch = x_fname_pat.search(email_text)\n",
    "        if catch:\n",
    "            x_fname = catch[0]\n",
    "    \n",
    "        # get body\n",
    "        m_body = ''\n",
    "        catch = m_body_pat.split(email_text, 1)\n",
    "        if catch:\n",
    "            m_body = catch[1]\n",
    "        \n",
    "        # create dictionary entry\n",
    "        wrangle_dict[email_path] = [m_id, m_date, m_from, m_to, \n",
    "                                    m_cc, m_bcc, m_subj, mime_vers, \n",
    "                                    cont_type, encode, x_from, x_to, \n",
    "                                    x_cc, x_bcc, x_fold, x_orig, \n",
    "                                    x_fname, m_body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import re library\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "# set regex patterns 'Message-ID'\n",
    "m_id_pat = re.compile('(?<=Message-ID: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Date'\n",
    "m_date_pat = re.compile('(?<=\\nDate: )[^\\n]*')\n",
    "    \n",
    "# set regex patterns 'From'\n",
    "m_from_pat = re.compile('(?<=\\nFrom: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'To'\n",
    "m_to_pat = re.compile('(?<=\\nTo: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Cc'\n",
    "m_cc_pat = re.compile('(?<=\\nCc: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Bcc'\n",
    "m_bcc_pat = re.compile('(?<=\\nBcc: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Subject'\n",
    "m_subj_pat = re.compile('(?<=\\nSubject: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Mime-Version'\n",
    "mime_vers_pat = re.compile('(?<=\\nMime-Version: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Content-Type'\n",
    "cont_type_pat = re.compile('(?<=\\nContent-Type: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'Content-Transfer-Encoding'\n",
    "encode_pat = re.compile('(?<=\\nContent-Transfer-Encoding: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'X-From'\n",
    "x_from_pat = re.compile('(?<=\\nX-From: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'X-To'\n",
    "x_to_pat = re.compile('(?<=\\nX-To: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'X-cc'\n",
    "x_cc_pat = re.compile('(?<=\\nX-cc: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'X-bcc'\n",
    "x_bcc_pat = re.compile('(?<=\\nX-bcc: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'X-Folder'\n",
    "x_fold_pat = re.compile('(?<=\\nX-Folder: )[^\\n]*')\n",
    "\n",
    "# set regex patterns 'X-Origin'\n",
    "x_orig_pat = re.compile('(?<=\\nX-Origin: )[^\\n]*')\n",
    "\n",
    "# set regex to return X-Filename, email body\n",
    "x_fname_pat = re.compile('(?<=\\nX-FileName: )[^\\n]*\\n\\n')\n",
    "\n",
    "# set regex patterns 'Body'\n",
    "m_body_pat = re.compile('\\nX-FileName: [^\\n]*\\n\\n')\n",
    "\n",
    "# initialize dictionary\n",
    "wrangle_dict = {}\n",
    "\n",
    "# concurrent futures executor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:  \n",
    "    future = executor.map(save_to_dict, email_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517401"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrangle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 19 columns):\n",
      "f_dir        517401 non-null object\n",
      "m_id         517401 non-null object\n",
      "m_date       517401 non-null object\n",
      "m_from       517401 non-null object\n",
      "m_to         517401 non-null object\n",
      "m_cc         517401 non-null object\n",
      "m_bcc        517401 non-null object\n",
      "m_subj       517401 non-null object\n",
      "mime_vers    517401 non-null object\n",
      "cont_type    517401 non-null object\n",
      "encode       517401 non-null object\n",
      "x_from       517401 non-null object\n",
      "x_to         517401 non-null object\n",
      "x_cc         517401 non-null object\n",
      "x_bcc        517401 non-null object\n",
      "x_fold       517401 non-null object\n",
      "x_orig       517401 non-null object\n",
      "x_fname      517401 non-null object\n",
      "m_body       517401 non-null object\n",
      "dtypes: object(19)\n",
      "memory usage: 75.0+ MB\n",
      "Wall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe from dictionary\n",
    "wrangle_frame = pd.DataFrame.from_dict(wrangle_dict, orient='index', columns = ['m_id', 'm_date', 'm_from', 'm_to', \n",
    "                                                                                'm_cc', 'm_bcc', 'm_subj', 'mime_vers', \n",
    "                                                                                'cont_type', 'encode', 'x_from', 'x_to', \n",
    "                                                                                'x_cc', 'x_bcc', 'x_fold', 'x_orig', \n",
    "                                                                                'x_fname', 'm_body'])\n",
    "\n",
    "# sort file directory names, pop it out to column\n",
    "wrangle_frame = wrangle_frame.sort_index().reset_index()\n",
    "\n",
    "# rename index column 'f_dir'\n",
    "wrangle_frame = wrangle_frame.rename(columns = {'index' : 'f_dir'})\n",
    "\n",
    "# export master to csv\n",
    "wrangle_frame.to_csv('./data/00_original_wrangle.csv', index=False, index_label=False)\n",
    "\n",
    "# check DataFrame\n",
    "wrangle_frame.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
